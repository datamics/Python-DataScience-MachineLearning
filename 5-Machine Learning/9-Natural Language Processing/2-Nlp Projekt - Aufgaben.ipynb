{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://datamics.com/de/courses/\"><img src=../../DATA/bg_datamics_top.png></a>\n",
    "\n",
    "<em text-align:center>© Datamics</em>\n",
    "# NLP Projekt - Aufgaben\n",
    "\n",
    "Willkommen zum NLP Projekt des Kurses. In diesem NLP Projekt werden wir versuchen Yelp Reviews in 1 Stern oder 5 Sterne Kategorien zu klassifizieren. Dazu nutzen wir den Text ihrere Bewertung. Dieses Prozedere wird leichter sein als das der Lektion, da wir die Pipeline für komplexe Aufgaben verwenden werden. \n",
    "\n",
    "Wir nutzen [Yelp Review Daten von Kaggle](https://www.kaggle.com/c/yelp-recsys-2013).\n",
    "\n",
    "Jede Beobachtung in dem Datensatz ist eine bestimmte Bewertung eines bestimmten Geschäfts durch einen bestimmten Nutzer.\n",
    "\n",
    "Die \"stars\" Spalte beinhaltet die Anzahl der Sterne (1 bis 5) die der Bewerter dem Geschäft verliehen hat. In anderne Worten: Die Bewertung des Geschäfts durch den Autor. \n",
    "\n",
    "Die \"cool\" Spalte beinhaltet die Anzahl der \"Cool\"-Votes der Bewertung durch andere Nutzer.\n",
    "\n",
    "Alle Bewertungen starten mit 0 \"Cool\"-Votes und es gibt nach oben kein Limit. Je mehr Leute die Bewertung \"Cool\" finden und sie so voten, desto höhere die Anzahl.\n",
    "\n",
    "Für die \"useful\" (dt. nützlich) und \"funny\" (dt. witzig) Spalten gilt das gleiche.\n",
    "\n",
    "Legen wir los! Folge den Anweisungen!\n",
    "\n",
    "## Imports\n",
    "\n",
    "**Importiere die üblichen Verdächtigen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Daten\n",
    "\n",
    "**Lese yelp.csv ein und setze es zu einem DataFrame namens \"yelp\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schaue dir den head, die info und die describe Methode des DataFrames an.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle eine neue Spalte namens \"text length\", die die Anzahl an Wörtern der \"text\" Spalte beinhaltet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "**Falls du es nicht schon oben getan hast: Importiere jetzt auch die Visualisierungs.Libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nutze FacetGrid von Seaborn, um ein Grid von 5 Histogrammen zu erzeugen. Diese sollen auf den \"stars\" basieren.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle ein Boxplot der Textlänge für jede Stern-Kategorie.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle ein Countplot für die Anzahl an Erscheinungen jeder Stern-Kategorie.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nutze groupby für die Stern-Kategorie, um den Durchschnittswert der numerischen Spalten zu erhalten. (Du sollst einen neuen DataFrame \"stars\" erhalten)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d88c0e796d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Dein Code hier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stars' is not defined"
     ]
    }
   ],
   "source": [
    "# Dein Code hier\n",
    "stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nutze die corr() Methode auf den groupby-DataFrame um diesen DataFrame zu erhalten:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nutze jetzt Seaborn, um eine Heatmap der Korrelationen zu erhalten.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Klassifizierungsaufgabe\n",
    "\n",
    "Fahren wir nun mit der eigentlichen Aufgabe fort. Um das ein wenig einfacher zu machen verwende nur die Bewertungen, die entweder einen oder fünf Sterne hatten.\n",
    "\n",
    "**Erstelle einen DataFrame namens \"yelp_class\", die alle Spalten aus dem yelp DataFrame beinhaltet, aber nur für 1 und 5 Sterne.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle zwei Objekte X und y. X wird der \"text\" aus yelp_class und y wird die \"stars\" sein.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importiere `CountVectorizer` und erstelle ein CountVectorizer Objekt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nutze die `fit_transform` Methode auf das CountVectorizer Objekt und übergebe X (die \"text\" Spalte). Speichere dieses Ergebnis, indem du X überschreibst.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "Teilen wir nun unsere Daten in Trainings- und Testset auf.\n",
    "\n",
    "**Nutze train_test_split, um die Daten in X_train, X_test, y_train und y_test zu teilen. Nutze test_size = 0.3 und random_state = 101.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Modell trainieren\n",
    "\n",
    "Es ist Zeit unser Modell zu trainieren.\n",
    "\n",
    "**Importiere MultinominalNB und erstelle eine Instanz des Schätzers namens nb.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jetzt fitte nb indem du die Trainingsdaten verwendest.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersagen und Auswertung\n",
    "\n",
    "Wir sollten nun überprüfen, wie sich unser Modell angstellt hat!\n",
    "\n",
    "**Nutze die `predict` Methode, um von nb ausgehend X_test vorherzusagen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle eine Confusion Matrix und einen Classification Report für diese Vorhersagen in Kombi mit y_test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toll! Schauen wir uns jetzt an, was passiert, wenn wir TF-IDF in den Prozess mit einbeziehen. Wir verwenden dazu die Pipeline.\n",
    "\n",
    "## Text Processing verwenden\n",
    "\n",
    "**Importiere `TfidfTransformer` von Scikit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importiere `Pipeline` von Scikit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle jetzt eine Pipeline mit den folgenden Schritten: CountVectorizer(), TfidfTransformer(), MultinominalNB().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Pipeline nutzen\n",
    "\n",
    "Zeit unsere Pipeline zu nutzen! Denke daran, dass die Pipeline alle Pre-Processing-Schritte enthält. Wir müssen die Original-Daten erneut aufteilen. Behalte dabei im Kopf, dass wir X vereits mit CountVecotized überschrieben haben. Wir wollen zuerst nur den Text.\n",
    "\n",
    "## Train Test Split\n",
    "\n",
    "**Führe den Train Test Split erneut für das yelp_class objekt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitte jetzt die Pipeline auf die Trainingsdaten. Denke daran, dass wir nicht die selben Trainingsdaten wie beim letzen Mal verwenden können, da diese bereits Vektorisiert wurden. Für unsere Pipeline brauchen wir nur den Text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersagen und Auswertung\n",
    "\n",
    "**Nutze jetzt die Pipeline um die Sterne für X_test vorherzusagen. Erstelle dann Classification Report und Confusion Matrix.**\n",
    "\n",
    "*Hinweis: Die Ergebnisse sollten komisch sein.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieht aus, als ob TF-IDF unsere Ergebnisse verschlechtert hat. Das war es für dieses Projekt. Falls du mit diesem letzen Ergebnis unzufireden bist gibt es einige Anrekungen, die du noch ausprobieren kannst:\n",
    "\n",
    "Versuche die Schritte der Pipeline anzupassen. Evtl. kannst du einen eigenen Analyzer erstellen (wie wir es in der Lektion getan haben). Oder verwende nur CountVectorizer() und NaiveBayes in der Pipeline. Oder hilft evtl. die Verwendung eines anderen ML-Klassifizierungsmodells?\n",
    "\n",
    "# Gut gemacht!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
